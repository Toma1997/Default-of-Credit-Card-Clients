# -*- coding: utf-8 -*-
"""DecisionTreePredictCreditDefault.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ep9DRzHYZhqRaVpVlQjCs4JNVzxp8I7J
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("/content/UCI_Credit_Card.csv")
df.head()

X=df.drop('default.payment.next.month', axis=1)
X= X.drop('ID', axis=1)
y=df['default.payment.next.month']

from sklearn.model_selection import train_test_split

# First divide train and test data in 70:30 ratio
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)

# Then further divide the test set in 50:50 ratio into validation set and test set
X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.50)

from sklearn.tree import DecisionTreeClassifier

dtree = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_leaf=25)
dtree.fit(X_train,y_train)

predictions = dtree.predict(X_val)
dtree.tree_.n_leaves

from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score

score1=accuracy_score(y_val,predictions)
print("Accuracy score: " + str(score1))

# Tree visualization

from sklearn.externals.six import StringIO 
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus

dot_data = StringIO()
export_graphviz(dtree, out_file=dot_data, feature_names = X.columns, class_names= ["0", "1"], filled=True, rounded=True, special_characters=True)
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
Image(graph.create_png())

from sklearn.tree.export import export_text
tree_rules = export_text(dtree, feature_names=list(X_train))
print(tree_rules)

def print_decision_tree(tree, feature_names, offset_unit='    '):    
  left      = tree.tree_.children_left
  right     = tree.tree_.children_right
  threshold = tree.tree_.threshold
  value = tree.tree_.value
  if feature_names is None:
      features  = ['f%d'%i for i in tree.tree_.feature]
  else:
      features  = [feature_names[i] for i in tree.tree_.feature]        

  def recurse(left, right, threshold, features, node, depth=0):
          offset = offset_unit*depth
          if (threshold[node] != -2):
                  print(offset+"if ( " + features[node] + " <= " + str(threshold[node]) + " ) {")
                  if left[node] != -1:
                          recurse (left, right, threshold, features,left[node],depth+1)
                  print(offset+"} else {")
                  if right[node] != -1:
                          recurse (left, right, threshold, features,right[node],depth+1)
                  print(offset+"}")
          else:
                  #print(offset,value[node]) 

                  #To remove values from node
                  temp=str(value[node])
                  mid=len(temp)//2
                  tempx=[]
                  tempy=[]
                  cnt=0
                  for i in temp:
                      if cnt<=mid:
                          tempx.append(i)
                          cnt+=1
                      else:
                          tempy.append(i)
                          cnt+=1
                  val_yes=[]
                  val_no=[]
                  res=[]
                  for j in tempx:
                      if j=="[" or j=="]" or j=="." or j==" ":
                          res.append(j)
                      else:
                          val_no.append(j)
                  for j in tempy:
                      if j=="[" or j=="]" or j=="." or j==" ":
                          res.append(j)
                      else:
                          val_yes.append(j)
                  val_yes = int("".join(map(str, val_yes)))
                  val_no = int("".join(map(str, val_no)))

                  if val_yes>val_no:
                      print(offset,'\033[1m',"YES")
                      print('\033[0m')
                  elif val_no>val_yes:
                      print(offset,'\033[1m',"NO")
                      print('\033[0m')
                  else:
                      print(offset,'\033[1m',"Tie")
                      print('\033[0m')

  recurse(left, right, threshold, features, 0,0)

print_decision_tree(dtree, X.columns)

val_acc_max_depth=[]
val_f1_max_depth=[]
train_acc_max_depth=[]
train_f1_max_depth=[]
for i in range(2,21):
    dtree = DecisionTreeClassifier(criterion='gini',max_depth=i,min_samples_leaf=25)
    dtree.fit(X_train,y_train)
    pred_train = dtree.predict(X_train)
    pred_val = dtree.predict(X_val)
    acc_train=accuracy_score(y_train,pred_train)
    f1_train = f1_score(y_train,pred_train,average='micro')
    acc_val=accuracy_score(y_val,pred_val)
    f1_val = f1_score(y_val,pred_val,average='micro')
    train_acc_max_depth.append(acc_train)
    train_f1_max_depth.append(f1_train)
    val_acc_max_depth.append(acc_val)
    val_f1_max_depth.append(f1_val)

plt.figure(figsize=(12,8))
plt.plot(range(2,21),train_acc_max_depth,c='red')
plt.plot(range(2,21),val_acc_max_depth,c='blue')
plt.legend(["Training","Validation"],fontsize=15)
plt.grid(True)
plt.xticks(fontsize=16)
plt.yticks(fontsize=16)
plt.xlabel("Max depth of the decision tree", fontsize=16)
plt.ylabel("Accuracy",fontsize=16)
plt.ylim(0.5,1.0)
plt.show()

val_acc_min_samples_leaf=[]
val_f1_min_samples_leaf=[]
train_acc_min_samples_leaf=[]
train_f1_min_samples_leaf=[]
for i in range(1,41):
    dtree = DecisionTreeClassifier(criterion='gini',max_depth=5,min_samples_leaf=i)
    dtree.fit(X_train,y_train)
    pred_train = dtree.predict(X_train)
    pred_val = dtree.predict(X_val)
    acc_train=accuracy_score(y_train,pred_train)
    f1_train = f1_score(y_train,pred_train,average='micro')
    acc_val=accuracy_score(y_val,pred_val)
    f1_val = f1_score(y_val,pred_val,average='micro')
    train_acc_min_samples_leaf.append(acc_train)
    train_f1_min_samples_leaf.append(f1_train)
    val_acc_min_samples_leaf.append(acc_val)
    val_f1_min_samples_leaf.append(f1_val)

plt.figure(figsize=(12,8))
plt.plot(range(1,41),train_acc_min_samples_leaf,c='red')
plt.plot(range(1,41),val_acc_min_samples_leaf,c='blue')
plt.legend(["Training","Validation"],fontsize=15)
plt.grid(True)
plt.xticks(fontsize=16)
plt.yticks(fontsize=16)
plt.xlabel("Minimum samples/leaf (max depth=5)", fontsize=16)
plt.ylabel("Accuracy",fontsize=16)
plt.ylim(0.5,1.0)
plt.show()